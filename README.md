# 加速点云
**1.26**   
&emsp;&emsp;尝试多线程。还是慢。  
**1.31**  
&emsp;&emsp;取消多线程，从降采样入手。上一届代码的多线程也没有用在这种地方，也没用到pcl的gpu加速版本，他们速度能跟上应该是检测出的框不大点云量少计算量少。  
19的核速度非常快，但降采样完就几百个点，拟合出的平面就几十个点。不太靠谱。  
对着电脑图：  
15核-点云数量2200-平面40-处理总时间2.8s 下采样1.5s 去离群0.11s 法线估计0.15S 拟合过滤平面1S  
&emsp;&emsp;输出结果不太对，飘得很厉害。Z轴不动都在1cm里面飘，X和Y更离谱，一会正一会负的，前后相差可达10cm。  
**2.1**  
&emsp;&emsp;我发现了，我没有清除点云，导致每次检测下采样的时间都在增加。  
深度转点云那里，如果我把3改成5，就会显示段错误。是我理解错了，那并不是手动降维，就是普通的深度转点云。  
修正后的速度（静止对着电脑两张黄色纯色图）：  
15核-200~300-63-总用时200-300ms XYZ在1cm范围内飘。总体效果还不错，就是速度还要再提升。    
**待测试**：  
1. 多个垂直平面与水平平面共存，是否能稳定检测想要的平面。  
2. 动态（高速振动）下是否能准确检测。  
3. 不同光线和颜色下是否能稳定检测（浅黄深黄都试一试，防止指橙为黄）  
# kinect的陀螺仪
**2.2 做了简单的积分+检验积分时间是否精确**  
&emsp;&emsp;分时操作系统准确执行30ms是个问题，没法像单片机一样调用定时器那么准确。先是用了$gettimeofday$得到微秒，用两次微秒相减和30ms对比判断。实践发现数据输出了几次就不再输出了，这个微秒超出位数限制后最高位就省掉了，这就导致前一次没超后一次超了两次差值就特别大。  
&emsp;&emsp;换了另一个计算时间的方法，有点浪费性能，但看网友测试的5ms版本还算准确，那我这个30ms应该可以忽略误差。但网友只测了短时间的数据，不知道长时间运行会不会因为什么不知名的bug出现偏差。  
出现了很神奇的bug。获取陀螺仪零点时访问imu数据的函数会抛出错误然后断掉这个程序（**该线程开了detach按理来说不影响主线程，可它两个一起断了**),把零点那段注释掉直接访问imu数据就不会报错。推测是因为申请的1000个float数组把内存占满了，没内存给imu存数据，给imu开个堆内存就可以。  
&emsp;&emsp;测试了一下，还算准确，慢慢移动个90度可能差个不到1度。但会有漂移。15min飘个4-5度，但把温漂标了之后应该会好很多（后来直接输出原始数据看了一下，其实原始数据并不怎么随温度漂移，这个误差应该是累积误差，只是因为温度也随时间增长给当成温漂了）。测试过程中还报错串口缓冲区开太大，但程序没有中断运行。（https://blog.csdn.net/OIDCAT/article/details/126271960）
&emsp;&emsp;但快速移动就不行了，我把它乱甩一通再放回原来的位置会差个20-30度。中速转一圈会差个5-6度。
**定时准确性的测试结果（不准确）**：跑五分钟，也就是让循环走10000次（实际跑了10001次）后用$gettimeofday$打印，打印结果为298.932s（第二次测试为298.928s）。但其实无法确定哪一个结果更准确，从原理上来说是$gettimeofday$更准确一点，毕竟它就是获取两次系统时间作差。那么假设验证用的函数是准确的，跑300.03s差了1.09s，约0.3%的误差率。但假如这差的1S里狗子都在以90度/s的速度旋转，那么结果就是差90度，很恐怖的数字。假设4S转完一圈，那么差了0.012S，结果差0.108度。

**2.3 再次检验积分时间是否精确**
&emsp;&emsp;今天又检查了一遍代码，发现把获取当前时间的代码放到了获取零点前面，导致误差变大。准确的测量结果如下。
**定时准确性的测试结果（准确）**：循环走10001次，$gettimeofday$打印用时300.030S（精度限制）。从结果来看定时的误差可以忽略不计。
&emsp;&emsp;再次测了一下角度，还是那样，慢慢地转一圈偏1-2度，中速偏5度左右，乱晃一通可达30度。又简单测了下传输速率，30ms大概能读84个数据（官方给出的是208Hz，也就是大约4ms一个，差得有点多）（根据后几天的重复检验，这里应该是测错了）。  

**2.4-2.5 加滤波+减少积分时间间隔**
&emsp;&emsp;将陀螺仪代码里的卡尔曼滤波、直通滤波还有更新零点都搬了过来，接收+处理数据一般少于0.2ms,但偶尔会蹦到1.1ms，不过问题不大，但是跟之前测的30ms接收84个数据差得有点多？
&emsp;&emsp;简单地正比例标定了正反转，原地中速转一圈的话误差在2度以内，水平向前或向后不会影响输出角度。但它对上下的振动非常敏感，垂直上下移动后就会偏个5-6度。这点得看在狗子上的表现再想如何解决了。还有标定，要精细标定的话得用陀螺仪标定架，但那电机我也不会整，好麻烦。所以目前能做的提高精度的尝试如下：  
1. 缩短积分时间   
2. 改变卡尔曼滤波系数看效果  
&emsp;&emsp;把timeout设为1ms的话，前面几千个数据会出现等待超时的情况，后面就不会了。在接收数据前设置休眠一段时间没用，光接收数据不做处理也没用（试了2000-20000），零点2000个数据中稳定地有990-1000个数据是超时的，零点首次更新后会超4个，之后接收30个数据+处理全都少于0.2ms，绝大部分少于0.1ms。这就非常奇怪了。按理说数据传输刚开始速率不稳定可以理解，但无论是等待还是接收后丢弃，都没有任何改善。  
&emsp;&emsp;最后的方案是零点数据接收时不设置等待时间。而更新后接收的第一组数据在超时四个的情况下也只用了4.564ms，再考虑小电脑的运算能力，完全可以把积分时间间隔设为10-15ms。这里设为10ms，小电脑带不动再调。  
&emsp;&emsp;好家伙，我改时间间隔居然报错每次都等待超时。这又不是硬中断，时间间隔不够跟你等待超不超时有啥关系？把等待数据的时间拉大，缩短时间间隔到14ms，会发现接收+处理数据的代码运行时间增加到了19.5ms。把时间间隔提升到20ms，会发现和30ms一样了，不超过0.2ms。怀疑是不是有个类似缓冲区的存在，在休眠的时间内也在接收数据。
**2.6 再验时间**   
&emsp;&emsp;再重新验一下接收30个数据而不做处理要多长时间。发现绝大部分都是19ms多，偶尔会有18ms,而在每三个19ms间会出现一次14ms，非常规律。鉴于官方文档没有对imu进行更详细的说明，就不探究这规律的14ms是怎么回事。这么看的话大概0.65ms接收一次数据。那之前那个0.2ms是咋来的呢？先证明计时函数的准确性。根据网上资料，gettimeofday()在linux的表现可能不准且年代久远，而chrono::high_resolution_clock::now()是C++11的函数，获取的是系统高精度时钟。于是我用chrono::high_resolution_clock::now()来及时，发现也是少于0.2ms，两个函数的差异是0.1us级别的，完全可以忽略差距。而sleep_until的精度就很差劲，应该留100us进行自旋的，测出来只留了20-50us不等。不过其实没什么影响，给验证时间精确度添了点麻烦。   
&emsp;&emsp;注释掉30ms定时的部分，只计算接收+处理数据的时间，发现和前面只接收的结果差不多，都是19ms/14ms，说明数据处理部分几乎不占性能。有意思的是出现了等待陀螺仪数据超时的提升（等待时长为5ms），而在注释前从没出现过这种情况。而只要在接收+处理数据的代码下有时延，无论是sleep_util还是while循环自旋直到now>tick，速度都会提升至0.2ms以内。除了缓冲区在利用这段时间在自动接收数据想不出其它解释。kInterval为20ms效果和30ms差不多，调到18ms就是无延时的效果了。每接收+处理五个数据显示一次时间，当kInterval为18ms时，发现每两组间的差距不是大约4.5ms就是几十us，有1差2不差3差4不差5或1差2差3不差4差5两种情况。而当kInterval为20ms时，每两组的差距在5us左右。
**猜测**：因为接收30个数据要19ms左右，kInterval为18ms时时间不够，定时相当于没有（超时了自然不会进入自旋的循环）。kInterval为20ms时，数据处理只需要几十us，剩余自旋的19ms刚好够缓冲区填满30个数据，所以0.2ms只是读+处理的用时，19ms的接收用时已经在延时中完成了。按推测，接收10个数据用时6.5ms，给定kInterval为8ms，测出来速度符合理论。  
&emsp;&emsp;把积分时间间隔改为10ms，一次用数据14个，应该是比30ms/30个精度要高的。明天标定一下看看效果如何。
**2.7 标定**
&emsp;&emsp;标了一下，跟之前好像也没多大区别，可能手动粗略标定上限也就这样了。对z轴加速的的抗干扰也没变好，小幅度的垂直移动还是会偏个6-7度。